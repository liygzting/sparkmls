# 计算回归模型
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import sklearn
import random
import os

from pyspark.sql import SparkSession
from pyspark.sql import SQLContext
from pyspark.sql.functions import mean, col, split, regexp_extract, when, lit
from pyspark.ml import Pipeline
from pyspark.ml.feature import StringIndexer, VectorAssembler, QuantileDiscretizer
from pyspark.ml.evaluation import MulticlassClassificationEvaluator


spark = SparkSession.builder.appName("datasets regression").getOrCreate()
df = spark.read.csv("../../../datas/hour.csv", header="True", inferSchema="True")


df.limit(3).toPandas()


print("The dataset has %d rows" % df.count())


df.printSchema()


df = df.drop("instant").drop("dteday").drop("casual").drop("registered")
df.limit(3).toPandas()


train, test = df.randomSplit([0.7, 0.3], seed=0)
print("There are %d training examples and %d test examples." % (train.count(), test.count()))


plt.figure(figsize=(10,5))
plt.title("Line of hr vs cnt")
sns.lineplot(data=train.select("hr","cnt").toPandas(), x="hr", y="cnt")


from pyspark.ml.feature import VectorAssembler, VectorIndexer

featuresCols = df.columns
featuresCols.remove("cnt")

vectorAssembler = VectorAssembler(inputCols=featuresCols, outputCol="rawFeatures")
vectorIndexer = VectorIndexer(inputCol="rawFeatures", outputCol="features", maxCategories=4)


from pyspark.ml.regression import GBTRegressor
gbt = GBTRegressor(labelCol="cnt")


from pyspark.ml.tuning import CrossValidator, ParamGridBuilder
from pyspark.ml.evaluation import RegressionEvaluator

paramGrid = ParamGridBuilder().addGrid(gbt.maxDepth, [2, 5]).addGrid(gbt.maxIter, [10, 100]).build()

evaluator = RegressionEvaluator(metricName="rmse", labelCol=gbt.getLabelCol(), predictionCol=gbt.getPredictionCol())

cv = CrossValidator(estimator=gbt, estimatorParamMaps=paramGrid, evaluator=evaluator)


from pyspark.ml import Pipeline

pipeline = Pipeline(stages=[vectorAssembler, vectorIndexer, cv])


pipelineModel = pipeline.fit(train)


predictions = pipelineModel.transform(test)


predictions.select("cnt", "prediction", *featuresCols).limit(3).toPandas()


rmse = evaluator.evaluate(predictions)
print("The RMSE is %g" % rmse)


plt.figure(figsize=(10,5))
plt.title("Predictions hr vs predictions")
sns.lineplot(data=predictions.select("hr", "prediction").toPandas(), x="hr", y="prediction")


import pyspark.sql.functions as F

predictions_with_residuals = predictions.withColumn("residual", (F.col("cnt") - F.col("prediction")))
predictions_with_residuals.agg({"residual":"mean"}).limit(3).toPandas()


plt.figure(figsize=(10, 5))
plt.title("Predictions Residual")
sns.barplot(predictions_with_residuals.select("hr", "residual").toPandas(), x="hr", y="residual")









