import os
import random
import sklearn
import seaborn as sns
import matplotlib.pyplot as plt

from pyspark.sql import SQLContext
from pyspark.sql import SparkSession
from pyspark.ml import Pipeline

from pyspark.sql.functions import mean, col, split, when, lit, isnan, count, regexp_extract
from pyspark.ml.feature import StringIndexer, VectorAssembler, QuantileDiscretizer
from pyspark.ml.evaluation import MulticlassClassificationEvaluator


spark = SparkSession.builder.appName("datasets classification").getOrCreate()
df = spark.read.csv("../../../datas/train.csv", header="True", inferSchema="True")


df.limit(3).toPandas()


df.printSchema()


pandas_df = df.toPandas()
plt.figure(figsize=(10, 5))
plt.title("Age distribute")
sns.distplot(pandas_df["Age"])


df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]).show()


df = df.drop("Cabin")  # missing over 50%


df = df.withColumn("Initial", regexp_extract(col("Name"), "([A-Za-z]+)\.", 1))
df.limit(3).toPandas()


df = df.replace(['Mlle','Mme', 'Ms', 'Dr','Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don'],
                        ['Miss','Miss','Miss','Mr','Mr',  'Mrs',  'Mrs',  'Other',  'Other','Other','Mr','Mr','Mr'])

df.groupby("Initial").avg("Age").collect()


df = df.withColumn("Age", when((df["Initial"] == "Miss") & (df["Age"].isNull()), 22).otherwise(df["Age"]))
df = df.withColumn("Age", when((df["Initial"] == "Other") & (df["Age"].isNull()), 46).otherwise(df["Age"]))
df = df.withColumn("Age", when((df["Initial"] == "Master") & (df["Age"].isNull()), 5).otherwise(df["Age"]))
df = df.withColumn("Age", when((df["Initial"] == "Mr") & (df["Age"].isNull()), 33).otherwise(df["Age"]))
df = df.withColumn("Age", when((df["Initial"] == "Mrs") & (df["Age"].isNull()), 36).otherwise(df["Age"]))


df.groupby("Embarked").count().show()


df = df.na.fill({"Embarked": "S"})  # 众数填充
df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]).show()


df = df.withColumn("Family_Size", col("SibSp")+col("Parch"))
df = df.withColumn("Alone", lit(0))
df = df.withColumn("Alone", when(df["Family_Size"] == 0, 1).otherwise(df["Alone"]))


# convert category to int
indexers = [StringIndexer(inputCol=column, outputCol=column+"_index").fit(df) for column in ["Sex","Embarked","Initial"]]
pipeline = Pipeline(stages=indexers)
df = pipeline.fit(df).transform(df)


df.limit(3).toPandas()


# "PassengerId","Name","Ticket","Cabin","Embarked","Sex","Initial"

df = df.drop("PassengerId","Name","Ticket","Cabin","Embarked","Sex","Initial")

feature = VectorAssembler(inputCols=df.columns[1:], outputCol="features")
feature_vector = feature.transform(df)
feature_vector.limit(3).toPandas()


(train_df, test_df) = feature_vector.randomSplit([0.8, 0.2], seed=111)
train_df.printSchema()


titanic_df = feature_vector.select(["features", "Survived"])
train_df, test_df = titanic_df.randomSplit([0.75, 0.25], seed=112)


from pyspark.ml.classification import LogisticRegression
from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit, CrossValidator
from pyspark.ml import Pipeline
from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator
from sklearn.metrics import roc_curve, auc



lr = LogisticRegression(labelCol="Survived")


paramGrid = ParamGridBuilder().addGrid(lr.regParam, (0.01, 0.1)).addGrid(lr.maxIter, (5, 10)).addGrid(lr.tol, (1e-4, 1e-5)).addGrid(lr.elasticNetParam, (0.25, 0.75)).build()


tvs = TrainValidationSplit(estimator=lr, estimatorParamMaps=paramGrid, evaluator=MulticlassClassificationEvaluator(labelCol="Survived"), trainRatio=0.8)


get_ipython().run_cell_magic("time", "", """
model = tvs.fit(train_df)""")


model_predictions = model.transform(test_df)


print("Accuracy", MulticlassClassificationEvaluator(labelCol="Survived", metricName="accuracy").evaluate(model_predictions))
print("Accuracy", MulticlassClassificationEvaluator(labelCol="Survived", metricName="weightedPrecision").evaluate(model_predictions))


model_predictions.printSchema()


print('Accuracy: ', MulticlassClassificationEvaluator(labelCol='Survived',metricName='accuracy').evaluate(model_predictions))
print('Precision: ',MulticlassClassificationEvaluator(labelCol='Survived',metricName='weightedPrecision').evaluate(model_predictions))


from pyspark.mllib.evaluation import BinaryClassificationMetrics as metric
from pyspark import SparkContext
sc = SparkContext.getOrCreate()
results = model_predictions.select("probability","Survived")
results_collect = results.collect()
results_list = [(float(i[0][0]), 1.0-float(i[1])) for i in results_collect]
scoreAndLabels = sc.parallelize(results_list)
metrics = metric(scoreAndLabels)
print("ROC is ", metrics.areaUnderROC)


from sklearn.metrics import roc_curve, auc

fpr = dict()
tpr = dict()
roc_auc = dict()

y_test = [i[1] for i in results_list]
y_score = [i[0] for i in results_list]

fpr, tpr, _ = roc_curve(y_true=y_test, y_score=y_score)
roc_auc = auc(fpr, tpr)

get_ipython().run_line_magic("matplotlib", " inline")
plt.figure()
plt.plot(fpr, tpr, label="ROC Curve (area=%0.2f)" % roc_auc)
plt.plot([0, 1], [0, 1], "k--")
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("Area under ROC Curve")
plt.legend(loc="lower right")
plt.show()



from pyspark.ml.classification import RandomForestClassifier
from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit

rf = RandomForestClassifier(labelCol="Survived")

paramGrid = ParamGridBuilder().addGrid(rf.maxDepth, [5, 10, 20]).addGrid(rf.maxBins, [20, 32, 50]).addGrid(rf.numTrees, [20, 40, 60]).addGrid(rf.impurity, ["gini", "entropy"]).addGrid(rf.minInstancesPerNode, [1, 5, 10]).build()

tvs = TrainValidationSplit(estimator=rf, estimatorParamMaps=paramGrid, evaluator=MulticlassClassificationEvaluator(labelCol="Survived"), trainRatio=0.8)
model = tvs.fit(train_df)
model_predictions = model.transform(test_df)

print("Acurracy is ", MulticlassClassificationEvaluator(labelCol="Survived", metricName="accuracy").evaluate(model_predictions))
print("Precision is ", MulticlassClassificationEvaluator(labelCol="Survived", metricName="weightedPrecision").evaluate(model_predictions))



sc =SparkContext.getOrCreate()   # We need to create SparkContext
results = model_predictions.select(['probability', 'Survived'])
 
## prepare score-label set
results_collect = results.collect()
results_list = [(float(i[0][0]), 1.0-float(i[1])) for i in results_collect]
scoreAndLabels = sc.parallelize(results_list)
 
metrics = metric(scoreAndLabels)
print("The ROC score is : ", metrics.areaUnderROC)


fpr = dict()
tpr = dict()
roc_auc = dict()
 
y_test = [i[1] for i in results_list]
y_score = [i[0] for i in results_list]
 
fpr, tpr, _ = roc_curve(y_test, y_score)
roc_auc = auc(fpr, tpr)
 
get_ipython().run_line_magic("matplotlib", " inline")
plt.figure()
plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Area under the ROC Curve')
plt.legend(loc="lower right")
plt.show()


get_ipython().run_cell_magic("time", "", """
from pyspark.ml.classification import GBTClassifier
gbt = GBTClassifier(labelCol="Survived")
paramGrid = ParamGridBuilder().addGrid(gbt.maxDepth, [5, 10, 20]).addGrid(gbt.maxBins, [20, 32, 50]).addGrid(gbt.maxIter, [10, 20, 30]).addGrid(gbt.minInstancesPerNode, [1, 5, 10]).build()

tvs = TrainValidationSplit(estimator=gbt
                           , estimatorParamMaps=paramGrid
                            ,evaluator=MulticlassClassificationEvaluator(labelCol='Survived')
                            ,trainRatio=0.8)

model = tvs.fit(train_df)
model_predictions= model.transform(test_df)

print('Accuracy: ', MulticlassClassificationEvaluator(labelCol='Survived',metricName='accuracy').evaluate(model_predictions))
print('Precision: ',MulticlassClassificationEvaluator(labelCol='Survived',metricName='weightedPrecision').evaluate(model_predictions))
""")


# 参考文档 https://blog.csdn.net/u010665216/article/details/124654878
# 参考文档2 https://github.com/shawshany/SparkML/blob/main/%E4%BD%BF%E7%94%A8Spark%E6%9E%84%E5%BB%BA%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B/%E4%BD%BF%E7%94%A8Spark%E6%9E%84%E5%BB%BA%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B.ipynb






